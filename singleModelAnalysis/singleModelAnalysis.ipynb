{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c43bbbc1",
   "metadata": {},
   "source": [
    "# Single Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2010c9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# b) Data extraction\n",
    "import os, base64\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET\n",
    "import rdflib\n",
    "import re\n",
    "from lxml import etree\n",
    "\n",
    "# c) General\n",
    "import copy\n",
    "import difflib\n",
    "import numpy as np\n",
    "from numpyencoder import NumpyEncoder\n",
    "import pandas as pd\n",
    "import math\n",
    "import operator as op\n",
    "import ast\n",
    "import re\n",
    "import string\n",
    "import csv\n",
    "import xlsxwriter\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "import ipyvuetify\n",
    "from ipywidgets import interact, interact_manual, interactive, IntSlider, FloatSlider\n",
    "from IPython.display import display, clear_output, Image, FileLink, HTML\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from PIL import Image\n",
    "from scipy.optimize import curve_fit\n",
    "from github import Github\n",
    "import requests\n",
    "\n",
    "# d) Plot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import markers\n",
    "import matplotlib.font_manager as font_manager\n",
    "import matplotlib.colors\n",
    "from pylab import rcParams\n",
    "import matplotlib.image as mpimg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da3774c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ontologies:\n",
    "# Save the .csv files of each ontology from https://bioportal.bioontology.org/ontologies\n",
    "FMA = pd.read_csv('./FMA.csv')\n",
    "CHEBI = pd.read_csv('./CHEBI.csv')\n",
    "OPB = pd.read_csv('./OPB.csv')\n",
    "GO = pd.read_csv('./GO.csv')\n",
    "\n",
    "# Extraction of IDs & Labels in the ontologies\n",
    "fmaID = FMA['Class ID']\n",
    "fmaLabel= FMA['Preferred Label']\n",
    "chebiID = CHEBI['Class ID']\n",
    "chebiLabel= CHEBI['Preferred Label']\n",
    "opbID = OPB['Class ID']\n",
    "opbLabel= OPB['Preferred Label']\n",
    "goID = GO['Class ID']\n",
    "goLabel= GO['Preferred Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f7c4328",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def githubSearch(fileName):\n",
    "    # github username\n",
    "    github_username = \"Niloofar-Sh\"\n",
    "\n",
    "    tokenFile = open('./github_access_token.txt','r')\n",
    "    github_access_token = tokenFile.read()\n",
    "\n",
    "    repository_name = \"static_website_Jlab\"\n",
    "    folder_path = 'singleModelAnalysis'\n",
    "\n",
    "    file_name = fileName+\".cellml\"  # The names of the files you want to search for\n",
    "\n",
    "    # Set up the authentication headers for the GitHub API\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {github_access_token}\"\n",
    "    }\n",
    "\n",
    "    # Get the contents of the folder\n",
    "    contents_url = f\"https://api.github.com/repos/{github_username}/{repository_name}/contents/{folder_path}\"\n",
    "    response = requests.get(contents_url, headers=headers)\n",
    "    response_json = response.json()\n",
    "\n",
    "    # Search for the file name among the list of files in the folder\n",
    "    file_found = False\n",
    "    for item in response_json:\n",
    "        if item[\"type\"] == \"file\" and item[\"name\"] == file_name:\n",
    "            file_found = True\n",
    "            file_url = item[\"html_url\"]\n",
    "            break\n",
    "\n",
    "    # Print the download URL of the file, if found\n",
    "    if file_found:\n",
    "        return file_url\n",
    "    else:\n",
    "        print(f\"File '{file_name}' not found in folder '{folder_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c1ecb20",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def rdfMeaning(meaning,var,el):\n",
    "    \n",
    "    if 'OPB' in el:\n",
    "        numCell=re.findall(r'\\d+', el)\n",
    "        for j in range(len(opbID)):\n",
    "            numID=re.findall(r'\\d+', opbID[j])\n",
    "            if numCell == numID:\n",
    "                meaning[var].append(opbLabel[j])\n",
    "    if 'CHEBI' in el:\n",
    "        numCell=re.findall(r'\\d+', el)\n",
    "        for j in range(len(chebiID)):\n",
    "            numID=re.findall(r'\\d+', chebiID[j])\n",
    "            if numCell == numID:\n",
    "                meaning[var].append(chebiLabel[j])\n",
    "    if 'GO' in el:\n",
    "        numCell=re.findall(r'\\d+', el)\n",
    "        for j in range(len(goID)):\n",
    "            numID=re.findall(r'\\d+', goID[j])\n",
    "            if numCell == numID:\n",
    "                meaning[var].append(goLabel[j])\n",
    "    if 'FMA' in el:\n",
    "        numCell=re.findall(r'\\d+', el)\n",
    "        for j in range(len(fmaID)):\n",
    "            numID=re.findall(r'\\d+', fmaID[j])\n",
    "            if numCell == numID:\n",
    "                meaning[var].append(fmaLabel[j])\n",
    "    if ('OPB' not in el) and ('CHEBI' not in el) and('GO' not in el) and ('FMA' not in el):\n",
    "        meaning[var].append(el)\n",
    "                \n",
    "    return meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e96aa64a",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Retreiving the annotations from the CellML parameter files\n",
    "def getAnnotations(add):\n",
    "    parser = etree.XMLParser(recover=True)\n",
    "    root = etree.parse(add, parser).getroot()\n",
    "    rdfGraph = rdflib.Graph()\n",
    "    for rdfElement in root.iter():\n",
    "        if rdfElement.tag.endswith('RDF'):\n",
    "            try:\n",
    "                rdfGraph.parse(data = etree.tostring(rdfElement), format=\"application/rdf+xml\")\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    def getLeaves(sbj, graph):\n",
    "        triples = list(graph.triples((sbj,None,None)))\n",
    "        leaves = []\n",
    "        if len(triples)>0:\n",
    "            for s, p, o in triples:\n",
    "                result =  getLeaves(o,graph)\n",
    "                leaves += result\n",
    "            return list(set(leaves))\n",
    "        else:\n",
    "            return [sbj]\n",
    "        \n",
    "    # Opens the CellML file and returns the list of variables names\n",
    "    f = open(add,'r')\n",
    "    text = f.read()\n",
    "    root = ET.fromstring(text)\n",
    "\n",
    "    rdfs = root.findall('{http://www.w3.org/1999/02/22-rdf-syntax-ns#}RDF')\n",
    "\n",
    "    List1=[]\n",
    "    for child in rdfs:\n",
    "        for grand in child:\n",
    "            List1.append(grand.attrib.get('{http://www.w3.org/1999/02/22-rdf-syntax-ns#}about'))\n",
    "    \n",
    "    List = list(dict.fromkeys(List1))\n",
    "    if '#metaid0' in List:\n",
    "        List.remove('#metaid0')\n",
    "        \n",
    "        \n",
    "    triplesList={}\n",
    "    for i in range(len(List)):\n",
    "        sbj = rdflib.URIRef(List[i])\n",
    "        triplesList[i]=getLeaves(sbj, rdfGraph)\n",
    "\n",
    "\n",
    "    rdfs=[]\n",
    "    \n",
    "    for item in triplesList:\n",
    "        d = []\n",
    "        for k in range(len(triplesList[item])):\n",
    "            if 'opb' in triplesList[item][k] or 'chebi' in triplesList[item][k] or 'fma' in triplesList[item][k] or 'go' in triplesList[item][k]: \n",
    "                lSplit= triplesList[item][k].split('/')\n",
    "                d.append(lSplit[-1])\n",
    "            else: # free-style descriptions!\n",
    "                d.append(str(triplesList[item][k]))\n",
    "    \n",
    "        rdfs.append(d)\n",
    "\n",
    "    for child in root:\n",
    "        if child.tag == '{http://www.cellml.org/cellml/1.1#}'+'component':\n",
    "            modelComponentName = child.attrib.get('name')\n",
    "    \n",
    "    \n",
    "    listP = []\n",
    "    for item in List:\n",
    "        for x in item.split('.'):\n",
    "            if '#'+modelComponentName == x:\n",
    "                itemP = item.replace(x+'.', '')\n",
    "                listP.append(itemP)\n",
    "                \n",
    "\n",
    "            \n",
    "    return [listP,rdfs,root]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16e4e3f7",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def valExtraction(root,List): \n",
    "    \n",
    "    init=[]; variables=[]; els=[]\n",
    "    \n",
    "    for child in root:\n",
    "        if child.tag == '{http://www.cellml.org/cellml/1.1#}'+'component':\n",
    "            modelComponentName = child.attrib.get('name')\n",
    "            \n",
    "    components = root.findall('{http://www.cellml.org/cellml/1.1#}component')\n",
    "    \n",
    "    for comp in components:\n",
    "        variables.append(comp.findall('{http://www.cellml.org/cellml/1.1#}variable'))\n",
    "        \n",
    "    for element in List:  \n",
    "        for var in variables:\n",
    "            for v in var:   \n",
    "                if modelComponentName+'.'+element == v.attrib['{http://www.cellml.org/metadata/1.0#}id']:\n",
    "                    if 'initial_value' in v.attrib: # if any initial value exists take it\n",
    "                        init.append(v.attrib['initial_value'])    \n",
    "                    else:\n",
    "                        init.append('None')\n",
    "    return init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c0b401b7",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    " def textFileGen(speciesNoDuplicate,kfkr_estimated,parametersData,meaning,reaction_reactants,V,N,reaction_products):\n",
    "\n",
    "#  def textFileGen(speciesNoDuplicate,parametersData,speciesConstants,reaction_reactants,V,N,reaction_products):\n",
    "    # Create a text file (TEXT)\n",
    "\n",
    "    unitsImport = ['def model composed_model as',\n",
    "                   '\\tdef import using \"units_BG.cellml\" for',\n",
    "                    '\\t\\tunit concentrationUnit using unit concentrationUnit;',\n",
    "                   '\\t\\tunit speciesConstantUnit using unit speciesConstantUnit;',\n",
    "                   '\\t\\tunit fluxUnit using unit fluxUnit;',\n",
    "                    '\\tenddef;',\n",
    "                  '\\tdef comp main as']\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    with open('GFG.txt', 'w') as fp:\n",
    "        pass    \n",
    "    with open('GFG.txt', 'a') as file:\n",
    "        for line in unitsImport:\n",
    "            file.write(line+'\\n')\n",
    "\n",
    "\n",
    "    with open('GFG.txt', 'a') as file:\n",
    "        file.write('\\t\\tvar t: second {init: 0};'+'\\n')\n",
    "\n",
    "    cellmlRef=[]        \n",
    "\n",
    "    q = ['q_{0}'.format(x) for x in range(1000)]\n",
    "    k=0\n",
    "    checkDup=[]\n",
    "    for species,i in zip(speciesNoDuplicate['speciesNoDuplicate'],range(len(speciesNoDuplicate['speciesNoDuplicate']))):\n",
    "            for transporterName,annotation in parametersData.items():\n",
    "                for value in annotation:\n",
    "                    if all(el in value[1] for el in species):\n",
    "                        flag=0; \n",
    "                        for j in range(len(checkDup)):\n",
    "                            if all(x in checkDup[j] for x in value[1]):\n",
    "                                flag=1\n",
    "\n",
    "                        if flag==0:\n",
    "                            checkDup.append(value[1])\n",
    "                            cellmlRef.append((value[1],q[k],'concentrationUnit'))\n",
    "                            with open('GFG.txt', 'a') as file:\n",
    "                                file.write('\\t\\tvar ' +q[k]+': '+'concentrationUnit '+'{'+'init: '+value[2]+'}'+';'+'\\n')\n",
    "                                k+=1\n",
    "\n",
    "\n",
    "    v = ['v_{0}'.format(x) for x in range(1000)]\n",
    "    k=0\n",
    "    for key in reaction_reactants:\n",
    "        for flux in reaction_reactants[key]:\n",
    "            cellmlRef.append((flux,v[k],'fluxUnit'))\n",
    "            with open('GFG.txt', 'a') as file:\n",
    "                file.write('\\t\\tvar '+v[k]+': '+'fluxUnit '+';'+'\\n')\n",
    "                k+=1\n",
    "\n",
    "\n",
    "    kf = ['kf_{0}'.format(x) for x in range(1000)]\n",
    "    kr = ['kr_{0}'.format(x) for x in range(1000)]\n",
    "    k=0\n",
    "    for key in V:\n",
    "        for flux,i in zip(V[key],range(len(V[key]))): \n",
    "            for value in parametersData[key]:\n",
    "                    if flux == value[0]:\n",
    "                        cellmlRef.append((value[1],kf[k],'fluxUnit'))\n",
    "\n",
    "                        with open('GFG.txt', 'a') as file:\n",
    "                            file.write('\\t\\tvar '+ kf[k]+': '+'fluxUnit '+'{'+'init: '+str(kfkr_estimated[key][flux]['kf'])+'}'+';'+'\\n')\n",
    "                            file.write('\\t\\tvar '+ kr[k]+': '+'fluxUnit '+'{'+'init: '+str(kfkr_estimated[key][flux]['kr'])+'}'+';'+'\\n')\n",
    "                            k+=1\n",
    "\n",
    "\n",
    "    # Generating the ODEs       \n",
    "    with open('GFG.txt', 'a') as file:\n",
    "        file.write('\\n')\n",
    "\n",
    "    for i in range(np.shape(N[singleSelection.value])[0]):\n",
    "        for annotation,ID,unit in cellmlRef:\n",
    "            if all(ele in annotation for ele in speciesNoDuplicate['speciesNoDuplicate'][i]):\n",
    "                with open('GFG.txt', 'a') as file:\n",
    "                    file.write('\\t\\tode('+ID+',t)=')\n",
    "                for j in range(np.shape(N[singleSelection.value])[1]):  \n",
    "                    if N[singleSelection.value][i][j] != 0:\n",
    "                        \n",
    "                        if N[singleSelection.value][i][j] > 0:\n",
    "                            for annotation2,ID2,unit2 in cellmlRef:\n",
    "                                \n",
    "                                if  all(el in annotation2 for el in V[singleSelection.value][j]):\n",
    "                                    with open('GFG.txt', 'a') as file:\n",
    "                                        file.write('+'+str(N[singleSelection.value][i][j])+'{dimensionless}*'+ID2)\n",
    "\n",
    "                    if N[singleSelection.value][i][j] < 0:\n",
    "                        for annotation2,ID2,unit2 in cellmlRef:\n",
    "                            if all(el in annotation2 for el in V[singleSelection.value][j]):\n",
    "                                with open('GFG.txt', 'a') as file:\n",
    "                                    file.write(str(N[singleSelection.value][i][j])+'{dimensionless}*'+ID2)\n",
    "\n",
    "        with open('GFG.txt', 'a') as file:\n",
    "            file.write(';\\n')\n",
    "\n",
    "\n",
    "    # Generating the reaction rates\n",
    "    with open('GFG.txt', 'a') as file:\n",
    "        file.write('\\n')\n",
    "\n",
    "    for flux,i in zip(V[singleSelection.value],range(len(V[singleSelection.value]))):\n",
    "        for annotation1,ID1,unit1 in cellmlRef:\n",
    "            if all(el in annotation1 for el in flux):\n",
    "                with open('GFG.txt', 'a') as file:\n",
    "                    file.write('\\t\\t '+ ID1+'= ') \n",
    "                    \n",
    "        with open('GFG.txt', 'a') as file:\n",
    "            file.write('(')\n",
    "        \n",
    "        if singleSelection.value=='SGLT1' and 'sodium(1+)' in meaning[flux+'_'+singleSelection.value]:\n",
    "            z_Na=1; F=96485; T=310; R=8.314; V_na=-0.046;\n",
    "            membraneContrib = math.exp((z_Na*F*V_na)/(R*T))\n",
    "            with open('GFG.txt', 'a') as file:\n",
    "                file.write(str(membraneContrib)+'{dimensionless}'+'*')\n",
    "\n",
    "        length = 0    \n",
    "        for key in reaction_reactants:\n",
    "            for stoi,reactant in reaction_reactants[key][flux]:\n",
    "                length+=1\n",
    "                with open('GFG.txt', 'a') as file:\n",
    "                    file.write('kf_'+str(i)+'*') \n",
    "                for annotation,ID,unit in cellmlRef:\n",
    "                    if all(el in reactant for el in annotation):\n",
    "                        with open('GFG.txt', 'a') as file:\n",
    "                            file.write('pow('+ID+','+str(stoi)+'{dimensionless}'+')') \n",
    "\n",
    "                if length < len(reaction_reactants[key][flux]):\n",
    "                    with open('GFG.txt', 'a') as file:\n",
    "                        file.write(' * ')\n",
    "                        \n",
    "\n",
    "\n",
    "            with open('GFG.txt', 'a') as file:\n",
    "                file.write(' - ')\n",
    "\n",
    "        length = 0 \n",
    "        for key in reaction_products:\n",
    "            for stoi,product in reaction_products[key][flux]:\n",
    "                length+=1\n",
    "                with open('GFG.txt', 'a') as file:\n",
    "                    file.write('kr_'+str(i)+'*') \n",
    "                for annotation,ID,unit in cellmlRef:\n",
    "                    if all(el in product for el in annotation):\n",
    "                        with open('GFG.txt', 'a') as file:\n",
    "                            file.write('pow('+ID+','+str(stoi)+'{dimensionless}'+')') \n",
    "\n",
    "                if length < len(reaction_products[key][flux]):\n",
    "                    with open('GFG.txt', 'a') as file:\n",
    "                        file.write(' * ')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        with open('GFG.txt', 'a') as file:\n",
    "            file.write(');\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with open('GFG.txt', 'a') as file:\n",
    "        file.write('\\tenddef;'+'\\n'+'enddef;')\n",
    "        \n",
    "    return cellmlRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8f1b226",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def pmrSearching(name):\n",
    "    sparqlendpoint = 'https://models.physiomeproject.org/pmr2_virtuoso_search'\n",
    "    sparql = SPARQLWrapper(sparqlendpoint)\n",
    "\n",
    "    def search_entity(terms):\n",
    "        query = \"\"\"SELECT ?graph ?Model_entity WHERE {{ GRAPH ?graph {{ ?Model_entity ?p ?o FILTER REGEX(LCASE(STR(?Model_entity)), '{terms}')}}}}\"\"\".format(terms=terms)\n",
    "        sparql.setQuery(query)\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        graphs = sparql.query().convert()\n",
    "        return graphs\n",
    "\n",
    "    def search_model(terms):\n",
    "        terms = terms.lower()\n",
    "        entities = search_entity(terms)\n",
    "        model = set()\n",
    "        for entity in entities['results']['bindings']:\n",
    "            workspace = entity['graph']['value']\n",
    "            cellml = entity['Model_entity']['value'].split('#')[0]\n",
    "            if not cellml.startswith('http') and terms in cellml.lower():\n",
    "                model.update([workspace+'/rawfile/HEAD/'+cellml])\n",
    "        return list(model)\n",
    "\n",
    "    pmrModel = search_model(name)\n",
    "\n",
    "    return pmrModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "168c1ce7",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def singleBGmodelBuilder(parametersData,inUse,reaction_reactants,reaction_products):\n",
    "\n",
    "    V = []\n",
    "    for key in reaction_reactants:\n",
    "        for flux in reaction_reactants[key]:\n",
    "            V.append(flux)\n",
    "\n",
    "    Species = []\n",
    "    for transporterName in parametersData:\n",
    "        for entity in parametersData[transporterName]:\n",
    "            if ('OPB_00340' in entity[1] and\n",
    "               'OPB_00592' not in entity[1] and\n",
    "               'OPB_01315' not in entity[1]):\n",
    "                X = copy.deepcopy(entity[1])\n",
    "                X.append(transporterName)\n",
    "                Species.append(X)\n",
    "\n",
    "    speciesNoDuplicate = []\n",
    "    for s in Species:\n",
    "        for transporterName in inUse:\n",
    "            if transporterName in s:\n",
    "                ss = copy.deepcopy(s)\n",
    "                ss.remove(transporterName)\n",
    "                if ss not in speciesNoDuplicate:\n",
    "                    speciesNoDuplicate.append(ss)\n",
    "  \n",
    "    M=np.zeros((len(Species),len(V)))\n",
    "    \n",
    "    for s in range(len(Species)):\n",
    "        for key in reaction_products:\n",
    "            for key2,i in zip(reaction_products[key],range(len(reaction_products[key]))):\n",
    "                for stoi,val  in reaction_products[key][key2]:\n",
    "                    if all(el in val+[key] for el in Species[s]):\n",
    "                        M[s][i] = float(stoi)\n",
    "        for key in reaction_reactants:\n",
    "            for key2,i in zip(reaction_reactants[key],range(len(reaction_reactants[key]))):\n",
    "                for stoi,val in reaction_reactants[key][key2]:\n",
    "                    if all(el in val+[key] for el in Species[s]):\n",
    "                        M[s][i] = -float(stoi)\n",
    "    \n",
    "    N=np.zeros((len(speciesNoDuplicate),len(V)))\n",
    "    for v,i in zip(V,range(len(V))):\n",
    "        for s1 in range(len(speciesNoDuplicate)):\n",
    "            for s2 in range(len(Species)):\n",
    "                if all(el in Species[s2] for el in speciesNoDuplicate[s1]):\n",
    "                    N[s1][i] = M[s2][i]\n",
    "\n",
    "    return [N,V,speciesNoDuplicate]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71a5a789",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def pmrRDFsearch(terms):\n",
    "    \n",
    "    sparqlendpoint = 'https://models.physiomeproject.org/pmr2_virtuoso_search'\n",
    "    sparql = SPARQLWrapper(sparqlendpoint)\n",
    "\n",
    "    sparql_tmpl = '''SELECT DISTINCT ?g ?v WHERE {{ GRAPH ?g {{\n",
    "    ?v ?p1 [?p2 ?b; ?p3 [?p4 ?d; ?p5 [?p6 ?f]]] .\n",
    "    FILTER (regex(str(?b),\"{opb}\") && regex(str(?d),\"{chebi}\") && regex(str(?f),\"{fma}\"))\n",
    "    }} }}'''\n",
    "\n",
    "    for c in terms:\n",
    "        if c.startswith('CHEBI'):\n",
    "            chebi = c\n",
    "        elif c.startswith('OPB'):\n",
    "            opb = c\n",
    "        elif c.startswith('FMA'):\n",
    "            fma = c\n",
    "    query = sparql_tmpl.format(opb=opb, chebi=chebi, fma=fma)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    rst =  sparql.query().convert()\n",
    "    if len(rst['results']['bindings']) > 0:\n",
    "        cellmls = {}\n",
    "        for r in rst['results']['bindings']:\n",
    "            cellml_file, cellml_var = r['v']['value'].split('#')\n",
    "            cellml_path = r['g']['value'] + '/rawfile/HEAD/' + cellml_file\n",
    "            if cellml_path not in cellmls:\n",
    "                cellmls[cellml_path] = []\n",
    "            cellmls[cellml_path] += [cellml_var]\n",
    "        return cellmls\n",
    "    return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0a6b28f",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Here we see which group of transporters/channels belong to which template\n",
    "templateGroups = {'type1':['GLUT2', 'X1', 'X2', 'X3', '...'],\n",
    "                  'type2':['SGLT1', 'Y1', 'Y2', 'Y3', '...']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c278af10",
   "metadata": {},
   "source": [
    "## Section 1: Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c89ac6e4",
   "metadata": {
    "code_folding": [
     14
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ebee3f9eb2946bcba40007eaa1be4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Dropdown(description='Select model:', options=('SGLT1', 'GLUT2', 'X1', 'X2', 'X3…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model Selection and BG structure demonstration\n",
    "singleSelection = widgets.Dropdown(\n",
    "            options=['SGLT1', 'GLUT2', 'X1', 'X2', 'X3', 'SGLT2', 'Y1', 'Y2', 'Y3', '...'],\n",
    "            description='Select model:',\n",
    "    style={'description_width': 'initial'},\n",
    "            disabled=False\n",
    "        )\n",
    "button_load = widgets.Button(\n",
    "                description='Load model',\n",
    "                tooltip='Load',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "output1 = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "def button_load_clicked(event):\n",
    "    with output1:\n",
    "        clear_output()\n",
    "        channelSelected = [singleSelection.value]\n",
    "        inUse={}\n",
    "        for selected in channelSelected:\n",
    "            for key in templateGroups.keys():\n",
    "                for transporterName,i in zip(templateGroups[key],range(len(templateGroups[key]))):\n",
    "                    if selected == transporterName:\n",
    "                        inUse[selected]=[]\n",
    "                        inUse[transporterName].append(key)\n",
    "                        \n",
    "        pmrModel = pmrSearching(singleSelection.value)\n",
    "        giturl = githubSearch(singleSelection.value)\n",
    "        \n",
    "#         print(f\"The template is <{inUse[singleSelection.value][0]}> with the link to the original model: {pmrModel}\")\n",
    "        print(f\"The original model <{singleSelection.value}> is deposited on: {giturl}\")\n",
    "\n",
    "        # Create an Output widget\n",
    "        out = widgets.Output()\n",
    "\n",
    "        # Create a button widget\n",
    "        button = widgets.Button(description='Show the structure')\n",
    "\n",
    "        # Define the path of the folder containing the images you want to display\n",
    "        folder_path = './figures'\n",
    "\n",
    "        # Define a function to display the images when the button is clicked\n",
    "        def display_images(button_click):\n",
    "            with out:\n",
    "                out.clear_output()\n",
    "                for file in os.listdir(folder_path):\n",
    "                    if file.strip('.jpg') == inUse[singleSelection.value][0] or \\\n",
    "                    file.strip('.JPG') == inUse[singleSelection.value][0] or \\\n",
    "                    file.strip('.JPEG') == inUse[singleSelection.value][0] or \\\n",
    "                    file.strip('.jpeg') == inUse[singleSelection.value][0]: \n",
    "                        file_path = os.path.join(folder_path, file)\n",
    "                        img = Image.open(file_path)\n",
    "                        new_image = img.resize((600, 400))\n",
    "                        text_0 = widgets.HTML(value=\"<h5><b>Bond graph structure of {}:<b><h5>\".format(file.strip('.jpg')))\n",
    "                        display(text_0,new_image)\n",
    "\n",
    "        # Attach the function to the button's on_click event\n",
    "        button.on_click(display_images)\n",
    "\n",
    "        # Display the widgets\n",
    "        display(button)\n",
    "        display(out)\n",
    "        \n",
    "button_load.on_click(button_load_clicked)\n",
    "vbox_result = widgets.VBox([button_load, output1])   \n",
    "\n",
    "vbox_text = widgets.VBox([singleSelection, vbox_result])\n",
    "page1 = widgets.HBox([vbox_text])\n",
    "\n",
    "display(page1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be13357",
   "metadata": {},
   "source": [
    "## Section 2: The Steady-states (SS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9b2f9682",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a277e32be04a99bbca217d258563db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Button(description='Show SS', layout=Layout(width='auto'), style=ButtonStyle(), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button_SS = widgets.Button(\n",
    "                description='Show SS',\n",
    "                tooltip='Description',\n",
    "                style={'description_width': 'initial'},\n",
    "                layout={'width': 'auto'}\n",
    "            )\n",
    "output2 = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "def button_SS_clicked(event):\n",
    "    with output2:\n",
    "        clear_output()\n",
    "        \n",
    "        channelSelected = [singleSelection.value]\n",
    "        inUse={}\n",
    "        for selected in channelSelected:\n",
    "            for key in templateGroups.keys():\n",
    "                for transporterName,i in zip(templateGroups[key],range(len(templateGroups[key]))):\n",
    "                    if selected == transporterName:\n",
    "                        inUse[selected]=[]\n",
    "                        inUse[transporterName].append(key)\n",
    "        \n",
    "        \n",
    "        \n",
    "        annotations={}\n",
    "        for transporterName in inUse:\n",
    "            \n",
    "            addressData = './{0}.csv'.format(transporterName+'_Data')\n",
    "            Data = pd.read_csv(addressData)\n",
    "            df_Data = pd.DataFrame(Data)\n",
    "            \n",
    "            addressP = './{0}.cellml'.format(singleSelection.value)\n",
    "            [List,rdfs,root] = getAnnotations(addressP)\n",
    "            initialVals = valExtraction(root,List)\n",
    "            annotations[transporterName] = []\n",
    "            annotations[transporterName] = [List,rdfs,initialVals]\n",
    "            \n",
    "        # Combining the model info in one dictionary ==> parametersData\n",
    "        parametersData = {}\n",
    "        for key in annotations:\n",
    "            parametersData[key] = []\n",
    "            for j in range(len(annotations[key][0])):\n",
    "                parametersData[key].append([annotations[key][0][j],annotations[key][1][j],annotations[key][2][j]])\n",
    "        \n",
    "        # Save the values in .json file\n",
    "        json_object = json.dumps(parametersData, indent=4, sort_keys=True,\n",
    "              separators=(', ', ': '), ensure_ascii=False,\n",
    "              cls=NumpyEncoder)\n",
    "        with open(\"parametersData.json\", \"w\") as outfile:\n",
    "            outfile.write(json_object)\n",
    "            \n",
    "            \n",
    "        SS = {}  \n",
    "        meaning = {} \n",
    "        for key,values in parametersData.items():\n",
    "            for value in values:\n",
    "                for item in df_Data.columns:\n",
    "                    if key+' | '+value[0] in item.split(' ('):\n",
    "                        SS[value[0]+'_'+key] = df_Data[item].iloc[-1]  \n",
    "                        if type(value[1])==list:\n",
    "                            meaning[value[0]+'_'+key]=[]\n",
    "                            for el in value[1]:\n",
    "                                meaning = rdfMeaning(meaning,value[0]+'_'+key,el)\n",
    "                                \n",
    "        # Save the SS values in SS.json file\n",
    "        json_object = json.dumps(SS, indent=4, sort_keys=True,\n",
    "              separators=(', ', ': '), ensure_ascii=False,\n",
    "              cls=NumpyEncoder)\n",
    "        with open(\"SS.json\", \"w\") as outfile:\n",
    "            outfile.write(json_object)\n",
    "            \n",
    "        # Save the meaning values in meaning.json file\n",
    "        json_object = json.dumps(meaning, indent=4, sort_keys=True,\n",
    "              separators=(', ', ': '), ensure_ascii=False,\n",
    "              cls=NumpyEncoder)\n",
    "        with open(\"meaning.json\", \"w\") as outfile:\n",
    "            outfile.write(json_object)\n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "        SSreaction={}\n",
    "        reaction_reactants = {}\n",
    "        reaction_products = {}\n",
    "\n",
    "        for key,vals in parametersData.items():\n",
    "            reaction_reactants[key]={}\n",
    "            reaction_products[key]={}\n",
    "            if key == 'SGLT1':\n",
    "                for val in vals:\n",
    "                    if 'OPB_00592' in val[1]:   # reaction finding\n",
    "                        SSreaction[val[0]] = SS[val[0]+'_'+key]\n",
    "                        reactionName = val[0]\n",
    "                        singleSpeciesRdf=copy.deepcopy(val[1])  # reaction to what species?\n",
    "                        singleSpeciesRdf.remove('OPB_00340')\n",
    "                        singleSpeciesRdf.remove('OPB_00592')\n",
    "                        reaction_reactants[key][reactionName]=[]\n",
    "                        reaction_products[key][reactionName]=[]\n",
    "\n",
    "                        for val0 in parametersData[key]:\n",
    "                            if ('FMA:70022' in val0[1] and # being reactant in SGLT1\n",
    "                                'OPB_00340' in val0[1] and # concentration Yes\n",
    "                                'OPB_00592' not in val0[1] and # reaction rate No\n",
    "                                'OPB_01315' not in val0[1] and # molecule No\n",
    "                                singleSpeciesRdf[0] in val0[1]):\n",
    "                                composedSpeciesRdf = copy.deepcopy(val0[1])                            \n",
    "                        for val1 in parametersData[key]:\n",
    "                            if (all(el in composedSpeciesRdf for el in val1[1]) and \n",
    "                                'OPB_00592' not in val1[1]):\n",
    "                                stoi=1\n",
    "                                for val2 in parametersData[key]:\n",
    "                                    if ('OPB_00340' in val2[1] and \n",
    "                                    'OPB_00592' not in val2[1] and \n",
    "                                    singleSpeciesRdf[0] in val2[1] and\n",
    "                                    'OPB_01315' in val2[1]):\n",
    "                                        stoi= copy.deepcopy(float(val2[2]))\n",
    "                                reaction_reactants[key][reactionName].append((stoi,composedSpeciesRdf))\n",
    "\n",
    "\n",
    "                        for val0 in parametersData[key]:\n",
    "                            if ('FMA:260691' in val0[1] and # being product in SGLT1\n",
    "                                'OPB_00340' in val0[1] and # concentration Yes\n",
    "                                'OPB_00592' not in val0[1] and # reaction rate No\n",
    "                                'OPB_01315' not in val0[1] and # molecule No\n",
    "                                singleSpeciesRdf[0] in val0[1]):\n",
    "                                composedSpeciesRdf = copy.deepcopy(val0[1])\n",
    "                        for val1 in parametersData[key]:\n",
    "                            if (all(el in composedSpeciesRdf for el in val1[1]) and \n",
    "                                'OPB_00592' not in val1[1]):\n",
    "                                stoi=1\n",
    "                                for val2 in parametersData[key]:\n",
    "                                    if ('OPB_00340' in val2[1] and \n",
    "                                    'OPB_00592' not in val2[1] and \n",
    "                                    singleSpeciesRdf[0] in val2[1] and\n",
    "                                    'OPB_01315' in val2[1]):\n",
    "                                        stoi= copy.deepcopy(float(val2[2]))\n",
    "                                reaction_products[key][reactionName].append((stoi,composedSpeciesRdf))\n",
    "\n",
    "            if key == 'GLUT2':\n",
    "                for val in vals:\n",
    "                    if 'OPB_00592' in val[1]:   # reaction finding\n",
    "                        SSreaction[val[0]] = SS[val[0]+'_'+key]\n",
    "                        reactionName = val[0]\n",
    "                        singleSpeciesRdf=copy.deepcopy(val[1])  # reaction to what species?\n",
    "                        singleSpeciesRdf.remove('OPB_00340')\n",
    "                        singleSpeciesRdf.remove('OPB_00592')\n",
    "                        reaction_reactants[key][reactionName]=[]\n",
    "                        reaction_products[key][reactionName]=[]\n",
    "                        \n",
    "                        for val0 in parametersData[key]:\n",
    "                            if ('FMA:226050' in val0[1] and # being reactant in GLUT2\n",
    "                                'OPB_00340' in val0[1] and # concentration Yes\n",
    "                                'OPB_00592' not in val0[1] and # reaction rate No\n",
    "                                'OPB_01315' not in val0[1] and # molecule No\n",
    "                                singleSpeciesRdf[0] in val0[1]):\n",
    "                                composedSpeciesRdf = copy.deepcopy(val0[1])                            \n",
    "                        for val1 in parametersData[key]:\n",
    "                            if (all(el in composedSpeciesRdf for el in val1[1]) and \n",
    "                                'OPB_00592' not in val1[1]):\n",
    "                                stoi=1\n",
    "                                for val2 in parametersData[key]:\n",
    "                                    if ('OPB_00340' in val2[1] and \n",
    "                                    'OPB_00592' not in val2[1] and \n",
    "                                    singleSpeciesRdf[0] in val2[1] and\n",
    "                                    'OPB_01315' in val2[1]):\n",
    "                                        stoi= copy.deepcopy(float(val2[2]))\n",
    "                                reaction_reactants[key][reactionName].append((stoi,composedSpeciesRdf))\n",
    "\n",
    "\n",
    "                        for val0 in parametersData[key]:\n",
    "                            if ('FMA:70022' in val0[1] and # being product in GLUT2\n",
    "                                'OPB_00340' in val0[1] and # concentration Yes\n",
    "                                'OPB_00592' not in val0[1] and # reaction rate No\n",
    "                                'OPB_01315' not in val0[1] and # molecule No\n",
    "                                singleSpeciesRdf[0] in val0[1]):\n",
    "                                composedSpeciesRdf = copy.deepcopy(val0[1])\n",
    "                        for val1 in parametersData[key]:\n",
    "                            if (all(el in composedSpeciesRdf for el in val1[1]) and \n",
    "                                'OPB_00592' not in val1[1]):\n",
    "                                stoi=1\n",
    "                                for val2 in parametersData[key]:\n",
    "                                    if ('OPB_00340' in val2[1] and \n",
    "                                    'OPB_00592' not in val2[1] and \n",
    "                                    singleSpeciesRdf[0] in val2[1] and\n",
    "                                    'OPB_01315' in val2[1]):\n",
    "                                        stoi= copy.deepcopy(float(val2[2]))\n",
    "                                reaction_products[key][reactionName].append((stoi,composedSpeciesRdf))\n",
    "                    \n",
    "         \n",
    "        # Save the values in .json file\n",
    "        json_object = json.dumps(reaction_reactants, indent=4, sort_keys=True,\n",
    "              separators=(', ', ': '), ensure_ascii=False,\n",
    "              cls=NumpyEncoder)\n",
    "        with open(\"reaction_reactants.json\", \"w\") as outfile:\n",
    "            outfile.write(json_object)\n",
    "            \n",
    "        json_object = json.dumps(reaction_products, indent=4, sort_keys=True,\n",
    "              separators=(', ', ': '), ensure_ascii=False,\n",
    "              cls=NumpyEncoder)\n",
    "        with open(\"reaction_products.json\", \"w\") as outfile:\n",
    "            outfile.write(json_object)     \n",
    "            \n",
    "            \n",
    "        [N,V,speciesNoDuplicate] = singleBGmodelBuilder(parametersData,inUse,reaction_reactants,reaction_products)      \n",
    "        \n",
    "        \n",
    "        # Save the values in .json file\n",
    "        N = {singleSelection.value:N}\n",
    "        V = {singleSelection.value:V}\n",
    "        json_object = json.dumps(N, indent=4, sort_keys=True,\n",
    "              separators=(', ', ': '), ensure_ascii=False,\n",
    "              cls=NumpyEncoder)\n",
    "        with open(\"N.json\", \"w\") as outfile:\n",
    "            outfile.write(json_object)\n",
    "            \n",
    "        json_object = json.dumps(V, indent=4, sort_keys=True,\n",
    "              separators=(', ', ': '), ensure_ascii=False,\n",
    "              cls=NumpyEncoder)\n",
    "        with open(\"V.json\", \"w\") as outfile:\n",
    "            outfile.write(json_object)\n",
    "            \n",
    "        S = {'speciesNoDuplicate': speciesNoDuplicate}\n",
    "        json_object = json.dumps(S, indent=4, sort_keys=True,\n",
    "              separators=(', ', ': '), ensure_ascii=False,\n",
    "              cls=NumpyEncoder)\n",
    "        with open(\"speciesNoDuplicate.json\", \"w\") as outfile:\n",
    "            outfile.write(json_object)\n",
    "            \n",
    "\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "        text_0 = widgets.HTML(value=\"<h5><b>Your selected protein {} has the following SS values:<b><h5>\".format(singleSelection.value))\n",
    "        display(text_0)\n",
    "        for key,val in meaning.items():\n",
    "            text_1 = widgets.HTML(value=\"<h5><b>{}:<b> {}<h5> <h5>{}<h5>\".format(key,SS[key],val))\n",
    "            display(text_1)\n",
    "        \n",
    "                \n",
    "button_SS.on_click(button_SS_clicked)\n",
    "vbox_result = widgets.VBox([button_SS, output2]) \n",
    "\n",
    "page2 = widgets.HBox([vbox_result])\n",
    "\n",
    "display(page2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bd4fe5",
   "metadata": {},
   "source": [
    "## Section 3: The kinetic values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "27dec9ac",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55485b025af4b6d945c00b0d8f9a494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Button(description='Estimate the kinetic parameters', layout=Layout(width='auto'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button_kfkr = widgets.Button(\n",
    "                description='Estimate the kinetic parameters',\n",
    "                tooltip='Description',\n",
    "                style={'description_width': 'initial'},\n",
    "                layout={'width': 'auto'}\n",
    "            )\n",
    "output3 = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "def button_kfkr_clicked(event):\n",
    "    with output3:\n",
    "        clear_output()\n",
    "\n",
    "\n",
    "        f = open(\"SS.json\")\n",
    "        SS = json.load(f)\n",
    "        f = open(\"N.json\")\n",
    "        N = json.load(f)\n",
    "        f = open(\"V.json\")\n",
    "        V = json.load(f)\n",
    "        f = open(\"reaction_reactants.json\")\n",
    "        reaction_reactants = json.load(f)\n",
    "        f = open(\"reaction_products.json\")\n",
    "        reaction_products = json.load(f)\n",
    "        f = open(\"meaning.json\")\n",
    "        meaning = json.load(f)\n",
    "        f = open(\"parametersData.json\")\n",
    "        parametersData = json.load(f)\n",
    "                \n",
    "        \n",
    "        reactionRates = {}\n",
    "        \n",
    "        for key in V:\n",
    "            reactionRates[key]={}\n",
    "            for reaction in V[key]:\n",
    "\n",
    "                reactantsSpecies=[]\n",
    "                productsSpecies=[]\n",
    "\n",
    "\n",
    "                solve=tuple()\n",
    "\n",
    "                for stoichiometry,reactant in reaction_reactants[key][reaction]:\n",
    "                    reactantsSpecies.append(reactant)       \n",
    "                    for val in parametersData[key]:\n",
    "                        if all(el in val[1] for el in reactant):\n",
    "                            solve=solve+(pow(SS[val[0]+'_'+key] ,stoichiometry),) \n",
    "\n",
    "\n",
    "                for stoichiometry,product in reaction_products[key][reaction]:\n",
    "                    productsSpecies.append(product)        \n",
    "                    for val in parametersData[key]:\n",
    "                        if all(el in val[1] for el in product):\n",
    "                            solve=solve+(pow(SS[val[0]+'_'+key] ,stoichiometry),) \n",
    "\n",
    "\n",
    "                def Na_VG(X, kf, kr):\n",
    "                    for x in range(0,len(reactantsSpecies)):\n",
    "\n",
    "                        reactants = 1 * X[x]            \n",
    "                    for x in range(len(reactantsSpecies),len(reactantsSpecies)+len(productsSpecies)):\n",
    "                        products = 1 * X[x]\n",
    "\n",
    "                    z_Na=1; F=96485; T=310; R=8.314; V_na=-0.046\n",
    "\n",
    "                    v = kf*1e6*reactants*math.exp((z_Na*F*V_na)/(R*T)) - kr*1e6*products\n",
    "                    # 1e6 added to all concentrations & rate because the values were too small\n",
    "                    # just like including compartments in SBML models\n",
    "                    return v\n",
    "\n",
    "                def func(X, kf, kr):\n",
    "\n",
    "                    for x in range(0,len(reactantsSpecies)):\n",
    "                        reactants = 1 * X[x]      \n",
    "                    for x in range(len(reactantsSpecies),len(reactantsSpecies)+len(productsSpecies)):\n",
    "                        products = 1 * X[x]\n",
    "\n",
    "                    v = kf*1e6*reactants - kr*1e6*products\n",
    "                    # 1e6 added to all concentrations & rate because the values were too small\n",
    "                    # just like including compartments in SBML models\n",
    "                    return v\n",
    "                \n",
    "                def diffusion(X, kfr):\n",
    "\n",
    "                    for x in range(0,len(reactantsSpecies)):\n",
    "                        reactants = 1 * X[x]      \n",
    "                    for x in range(len(reactantsSpecies),len(reactantsSpecies)+len(productsSpecies)):\n",
    "                        products = 1 * X[x]\n",
    "\n",
    "                    v = kfr*1e6*reactants - kfr*1e6*products\n",
    "                    # 1e6 added to all concentrations & rate because the values were too small\n",
    "                    # just like including compartments in SBML models\n",
    "                    return v\n",
    "\n",
    "                \n",
    "\n",
    "                if key=='SGLT1' and 'sodium(1+)' in meaning[reaction+'_'+key]:\n",
    "                    bounds=[[0,0],[np.inf,np.inf]]\n",
    "                    popt, pcov = curve_fit(Na_VG,solve,1e6*SS[reaction+'_'+key], maxfev=3000000, bounds=bounds)\n",
    "                    reactionRates[key][reaction]={}\n",
    "                    reactionRates[key][reaction]['kf'] = popt[0] \n",
    "                    reactionRates[key][reaction]['kr'] = popt[1]\n",
    "                if key=='SGLT1' and 'sodium(1+)' not in meaning[reaction+'_'+key]:\n",
    "                    bounds=[[0,0],[np.inf,np.inf]]\n",
    "                    popt, pcov = curve_fit(func,solve,1e6*SS[reaction+'_'+key], maxfev=3000000, bounds=bounds)\n",
    "                    reactionRates[key][reaction]={}\n",
    "                    reactionRates[key][reaction]['kf'] = popt[0] \n",
    "                    reactionRates[key][reaction]['kr'] = popt[1]\n",
    "                if key=='GLUT2':\n",
    "                    bounds=[[0],[np.inf]]\n",
    "                    popt, pcov = curve_fit(diffusion,solve,1e6*SS[reaction+'_'+key], maxfev=3000000, bounds=bounds)\n",
    "                    reactionRates[key][reaction]={}\n",
    "                    reactionRates[key][reaction]['kf'] = popt[0] \n",
    "                    reactionRates[key][reaction]['kr'] = popt[0]\n",
    "\n",
    "                print(reaction,':',reactionRates[key][reaction])\n",
    "\n",
    "\n",
    "        text_0 = widgets.HTML(value=\"<h5><b>where:<b><h5>\")\n",
    "        display(text_0)\n",
    "        for key,val in V.items():\n",
    "            for reaction in val:\n",
    "                text_1 = widgets.HTML(value=\"<h5><b>{}:<b><h5> <h5>{}<h5>\".format(reaction,meaning[reaction+'_'+key]))\n",
    "                display(text_1)\n",
    "\n",
    "\n",
    "         # Create the export button widget\n",
    "        button_export = widgets.Button(description='Export the values')\n",
    "        output4 = widgets.Output()\n",
    "        # Define a function to handle the button click event\n",
    "        def export_values(button_export):\n",
    "            with output4:\n",
    "                clear_output()\n",
    "                # Save the values in .json file\n",
    "                json_object = json.dumps(reactionRates, indent=4, sort_keys=True,\n",
    "                      separators=(', ', ': '), ensure_ascii=False,\n",
    "                      cls=NumpyEncoder)\n",
    "                with open(\"kfkr_estimated.json\", \"w\") as outfile:\n",
    "                    outfile.write(json_object)\n",
    "                text_2 = widgets.HTML(value=\"<h5>Estimated values for kf and kr saved to kfkr_estimated.json<h5>\")\n",
    "                display(text_2)\n",
    "\n",
    "        # Attach the save_number function to the button click event\n",
    "        button_export.on_click(export_values)\n",
    "        # Display the widgets\n",
    "        vbox_result = widgets.VBox([button_export, output4]) \n",
    "        page4 = widgets.HBox([vbox_result])\n",
    "        display(page4)\n",
    "\n",
    "      \n",
    "        \n",
    "button_kfkr.on_click(button_kfkr_clicked)\n",
    "vbox_result = widgets.VBox([button_kfkr, output3]) \n",
    "\n",
    "page3 = widgets.HBox([vbox_result])\n",
    "\n",
    "display(page3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69466166",
   "metadata": {},
   "source": [
    "## Section 4: BG model generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c7a2b3d7",
   "metadata": {
    "code_folding": [
     7
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49296ec5506c4e2a8dd97763f6ecd1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='Generate code', style=ButtonStyle(), tooltip='Description'), Output(layout=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button_cellml = widgets.Button(\n",
    "                description='Generate code',\n",
    "                tooltip='Description',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "output5 = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "def on_button_clicked5(event):\n",
    "    with output5:\n",
    "        f = open(\"N.json\")\n",
    "        N = json.load(f)\n",
    "        f = open(\"V.json\")\n",
    "        V = json.load(f)\n",
    "        f = open(\"speciesNoDuplicate.json\")\n",
    "        speciesNoDuplicate = json.load(f)\n",
    "        f = open(\"reaction_reactants.json\")\n",
    "        reaction_reactants = json.load(f)\n",
    "        f = open(\"reaction_products.json\")\n",
    "        reaction_products = json.load(f)\n",
    "        f = open(\"kfkr_estimated.json\")\n",
    "        kfkr_estimated = json.load(f)\n",
    "        f = open(\"parametersData.json\")\n",
    "        parametersData = json.load(f)\n",
    "        f = open(\"meaning.json\")\n",
    "        meaning = json.load(f)\n",
    "\n",
    "\n",
    "        cellmlRef = textFileGen(speciesNoDuplicate,kfkr_estimated,parametersData,meaning,reaction_reactants,V,N,reaction_products)\n",
    "        text_0 = widgets.HTML(value=\"<h3>The CellML code for the bond graph form of {} at Steady State is:</h3>\".format(singleSelection.value))\n",
    "        vbox_text = widgets.VBox([text_0])\n",
    "        display(vbox_text)\n",
    "        with open('GFG.txt') as f:\n",
    "            contents = f.read()\n",
    "        print(contents)\n",
    "\n",
    "button_cellml.on_click(on_button_clicked5)\n",
    "vbox_result = widgets.VBox([button_cellml, output5]) \n",
    "display(vbox_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296781cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
