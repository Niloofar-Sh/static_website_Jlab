{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Jupyter Notebook to generate a CellML file for the selected structures in the Generic Cell Flatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN THIS CELL IF IT'S THE FIRST TIME USING IPYWIDGETS & VOILA\n",
    "# !jupyter nbextension enable --py widgetsnbextension --sys-prefix\n",
    "# !jupyter serverextension enable voila --sys-prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# b) Data extraction\n",
    "import os, base64\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET\n",
    "import rdflib\n",
    "import re\n",
    "from lxml import etree\n",
    "\n",
    "# c) General\n",
    "import copy\n",
    "import difflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import operator as op\n",
    "import ast\n",
    "import re\n",
    "import string\n",
    "import csv\n",
    "import xlsxwriter\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual, interactive, IntSlider, FloatSlider\n",
    "from IPython.display import display, clear_output, Image, FileLink, HTML\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# d) Plot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import markers\n",
    "import matplotlib.font_manager as font_manager\n",
    "import matplotlib.colors\n",
    "from pylab import rcParams\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Retreiving the annotations from the CellML parameter files\n",
    "def getAnnotations(add):\n",
    "    parser = etree.XMLParser(recover=True)\n",
    "    root = etree.parse(add, parser).getroot()\n",
    "    rdfGraph = rdflib.Graph()\n",
    "    for rdfElement in root.iter():\n",
    "        if rdfElement.tag.endswith('RDF'):\n",
    "            try:\n",
    "                rdfGraph.parse(data = etree.tostring(rdfElement), format=\"application/rdf+xml\")\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    def getLeaves(sbj, graph):\n",
    "        triples = list(graph.triples((sbj,None,None)))\n",
    "        leaves = []\n",
    "        if len(triples)>0:\n",
    "            for s, p, o in triples:\n",
    "                result =  getLeaves(o,graph)\n",
    "                leaves += result\n",
    "            return list(set(leaves))\n",
    "        else:\n",
    "            return [sbj]\n",
    "        \n",
    "    # Opens the CellML file and returns the list of variables names\n",
    "    f = open(add,'r')\n",
    "    text = f.read()\n",
    "    root = ET.fromstring(text)\n",
    "\n",
    "    rdfs = root.findall('{http://www.w3.org/1999/02/22-rdf-syntax-ns#}RDF')\n",
    "\n",
    "    List1=[]\n",
    "    for child in rdfs:\n",
    "        for grand in child:\n",
    "            List1.append(grand.attrib.get('{http://www.w3.org/1999/02/22-rdf-syntax-ns#}about'))\n",
    "    \n",
    "    List = list(dict.fromkeys(List1))\n",
    "    if '#metaid0' in List:\n",
    "        List.remove('#metaid0')\n",
    "        \n",
    "        \n",
    "    triplesList={}\n",
    "    for i in range(len(List)):\n",
    "        sbj = rdflib.URIRef(List[i])\n",
    "        triplesList[i]=getLeaves(sbj, rdfGraph)\n",
    "\n",
    "\n",
    "    rdfs=[]\n",
    "    \n",
    "    for item in triplesList:\n",
    "        d = []\n",
    "        for k in range(len(triplesList[item])):\n",
    "            if 'opb' in triplesList[item][k] or 'chebi' in triplesList[item][k] or 'fma' in triplesList[item][k] or 'go' in triplesList[item][k]: \n",
    "                lSplit= triplesList[item][k].split('/')\n",
    "                d.append(lSplit[-1])\n",
    "            else: # free-style descriptions!\n",
    "                d.append(str(triplesList[item][k]))\n",
    "    \n",
    "        rdfs.append(d)\n",
    "\n",
    "    for child in root:\n",
    "        if child.tag == '{http://www.cellml.org/cellml/1.1#}'+'component':\n",
    "            modelComponentName = child.attrib.get('name')\n",
    "    \n",
    "    \n",
    "    listP = []\n",
    "    for item in List:\n",
    "        for x in item.split('.'):\n",
    "            if '#'+modelComponentName == x:\n",
    "                itemP = item.replace(x+'.', '')\n",
    "                listP.append(itemP)\n",
    "                \n",
    "\n",
    "            \n",
    "    return [listP,rdfs,root]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def valExtraction(root,List): \n",
    "    \n",
    "    init=[]; variables=[]; els=[]\n",
    "    \n",
    "    for child in root:\n",
    "        if child.tag == '{http://www.cellml.org/cellml/1.1#}'+'component':\n",
    "            modelComponentName = child.attrib.get('name')\n",
    "            \n",
    "    components = root.findall('{http://www.cellml.org/cellml/1.1#}component')\n",
    "    \n",
    "    for comp in components:\n",
    "        variables.append(comp.findall('{http://www.cellml.org/cellml/1.1#}variable'))\n",
    "        \n",
    "    for element in List:  \n",
    "        for var in variables:\n",
    "            for v in var:   \n",
    "                if modelComponentName+'.'+element == v.attrib['{http://www.cellml.org/metadata/1.0#}id']:\n",
    "                    if 'initial_value' in v.attrib: # if any initial value exists take it\n",
    "                        init.append(v.attrib['initial_value'])    \n",
    "                    else:\n",
    "                        init.append(None)\n",
    "    return init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def checkMutual(parametersData):\n",
    "\n",
    "    repeat = []\n",
    "    mutualVars={}\n",
    "    commonAnnotsDiffVals = {}; CommonAmountsAA = {}; CommonAmountsBB = {};\n",
    "    for k1 in range(len(list(parametersData))):\n",
    "        for k2 in range(len(list(parametersData))):\n",
    "            if list(parametersData)[k1] != list(parametersData)[k2] and (list(parametersData)[k1],list(parametersData)[k2]) not in repeat and (list(parametersData)[k2],list(parametersData)[k1]) not in repeat:    \n",
    "                if (list(parametersData.keys())[k1],list(parametersData.keys())[k2]) not in mutualVars:\n",
    "                    mutualVars[(list(parametersData.keys())[k1],list(parametersData.keys())[k2])]=[]\n",
    "\n",
    "                for i1 in range(len(list(parametersData.values())[k1])):\n",
    "                    for i2 in range(len(list(parametersData.values())[k2])):\n",
    "                        if all(elem in list(parametersData.values())[k1][i1][1] for elem in list(parametersData.values())[k2][i2][1]):\n",
    "                            repeat.append((list(parametersData)[k1],list(parametersData)[k2]))\n",
    "\n",
    "                            mutualVars[(list(parametersData.keys())[k1],list(parametersData.keys())[k2])].append(list(parametersData.values())[k1][i1][0])\n",
    "                            mutualVars[(list(parametersData.keys())[k1],list(parametersData.keys())[k2])].append(list(parametersData.values())[k1][i1][1])\n",
    "\n",
    "                            if list(parametersData.values())[k1][i1][2] != list(parametersData.values())[k2][i2][2]:\n",
    "\n",
    "                                if (list(parametersData.keys())[k1],list(parametersData.keys())[k2]) not in commonAnnotsDiffVals:\n",
    "                                    commonAnnotsDiffVals[(list(parametersData.keys())[k1],list(parametersData.keys())[k2])]=[]\n",
    "                                    CommonAmountsAA[(list(parametersData.keys())[k1],list(parametersData.keys())[k2])] = []\n",
    "                                    CommonAmountsBB[(list(parametersData.keys())[k1],list(parametersData.keys())[k2])] = []\n",
    "\n",
    "                                commonAnnotsDiffVals[(list(parametersData.keys())[k1],list(parametersData.keys())[k2])].append(list(parametersData.values())[k1][i1][1])\n",
    "                                CommonAmountsAA[(list(parametersData.keys())[k1],list(parametersData.keys())[k2])].append(list(parametersData.values())[k1][i1][2])\n",
    "                                CommonAmountsBB[(list(parametersData.keys())[k1],list(parametersData.keys())[k2])].append(list(parametersData.values())[k2][i2][2])\n",
    "\n",
    "    # Getting the preferred value from the user for the recognised same variables with different values\n",
    "    for i in range(len(list(commonAnnotsDiffVals.keys()))):\n",
    "        for j in range(len(list(commonAnnotsDiffVals.values())[i])):\n",
    "            print('Different values found for: ')\n",
    "            print('\\n')\n",
    "            print(list(commonAnnotsDiffVals.values())[i][j] ,list(commonAnnotsDiffVals.keys())[i],':',list(CommonAmountsAA.values())[i][j],  'and' , list(CommonAmountsBB.values())[i][j])   \n",
    "            list(CommonAmountsAA.values())[i][j]=copy.deepcopy(input('Enter the preferred value:'))\n",
    "\n",
    "\n",
    "    # Copying the changed values to the list of initial amounts of the model    \n",
    "    for mutualTransporters in commonAnnotsDiffVals: # (x,y)\n",
    "        for val1,i in zip(commonAnnotsDiffVals[mutualTransporters],range(len(commonAnnotsDiffVals[mutualTransporters]))):\n",
    "            for transporterName in parametersData: \n",
    "                for val2 in parametersData[transporterName]:\n",
    "                    if transporterName == mutualTransporters[0] and all(elem in val1 for elem in val2[1]):\n",
    "                        val2[2] = copy.deepcopy(CommonAmountsAA[mutualTransporters][i])\n",
    "                    if transporterName == mutualTransporters[1] and all(elem in val1 for elem in val2[1]):\n",
    "                        val2[2] = copy.deepcopy(CommonAmountsAA[mutualTransporters][i])\n",
    "\n",
    "    return [parametersData,mutualVars]               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    " def textFileGen(speciesNoDuplicate,parametersData,speciesConstants,reaction_reactants,V,N,reaction_products):\n",
    "    # Create a text file (TEXT)\n",
    "\n",
    "    unitsImport = ['def model composed_model as',\n",
    "                   '\\tdef import using \"units_BG.cellml\" for',\n",
    "                    '\\t\\tunit concentrationUnit using unit concentrationUnit;',\n",
    "                   '\\t\\tunit speciesConstantUnit using unit speciesConstantUnit;',\n",
    "                   '\\t\\tunit fluxUnit using unit fluxUnit;',\n",
    "                    '\\tenddef;',\n",
    "                  '\\tdef comp main as']\n",
    "\n",
    "    with open('GFG.txt', 'w') as fp:\n",
    "        pass    \n",
    "    with open('GFG.txt', 'a') as file:\n",
    "        for line in unitsImport:\n",
    "            file.write(line+'\\n')\n",
    "\n",
    "\n",
    "    with open('GFG.txt', 'a') as file:\n",
    "        file.write('\\t\\tvar t: second {init: 0};'+'\\n')\n",
    "\n",
    "    cellmlRef=[]        \n",
    "\n",
    "    q = ['q_{0}'.format(x) for x in range(1000)]\n",
    "    k=0\n",
    "    checkDup=[]\n",
    "    for species,i in zip(speciesNoDuplicate,range(len(speciesNoDuplicate))):\n",
    "            for transporterName,annotation in parametersData.items():\n",
    "                for value in annotation:\n",
    "                    if all(el in value[1] for el in species):\n",
    "                        flag=0; \n",
    "                        for j in range(len(checkDup)):\n",
    "                            if all(x in checkDup[j] for x in value[1]):\n",
    "                                flag=1\n",
    "\n",
    "                        if flag==0:\n",
    "                            checkDup.append(value[1])\n",
    "                            cellmlRef.append((value[1],q[k],'concentrationUnit'))\n",
    "                            with open('GFG.txt', 'a') as file:\n",
    "                                file.write('\\t\\tvar ' +q[k]+': '+'concentrationUnit '+'{'+'init: '+value[2]+'}'+';'+'\\n')\n",
    "                                k+=1\n",
    "\n",
    "    K = ['K_{0}'.format(x) for x in range(1000)]\n",
    "    k=0\n",
    "    checkDup=[]\n",
    "    for constant,i in zip(speciesConstants,range(len(speciesConstants))):\n",
    "        for transporterName,annotation in parametersData.items():\n",
    "            for value in annotation:\n",
    "                if all(el in value[1] for el in constant):\n",
    "                    flag=0; \n",
    "                    for j in range(len(checkDup)):\n",
    "                        if all(x in checkDup[j] for x in value[1]):\n",
    "                            flag=1\n",
    "\n",
    "                    if flag==0:\n",
    "                        checkDup.append(value[1])\n",
    "                        cellmlRef.append((value[1],K[k],'speciesConstantUnit'))\n",
    "                        with open('GFG.txt', 'a') as file:\n",
    "                            file.write('\\t\\tvar '+K[k]+': '+'speciesConstantUnit '+'{'+'init: '+value[2]+'}'+';'+'\\n')\n",
    "                            k+=1     \n",
    "\n",
    "\n",
    "    v = ['v_{0}'.format(x) for x in range(1000)]\n",
    "    k=0\n",
    "    for flux in reaction_reactants:\n",
    "        cellmlRef.append((flux,v[k],'fluxUnit'))\n",
    "        with open('GFG.txt', 'a') as file:\n",
    "            file.write('\\t\\tvar '+v[k]+': '+'fluxUnit '+';'+'\\n')\n",
    "            k+=1\n",
    "\n",
    "\n",
    "    kappa = ['kappa_{0}'.format(x) for x in range(1000)]\n",
    "    k=0\n",
    "    for flux,i in zip(V,range(len(V))): \n",
    "        for transporterName,annotation in parametersData.items():\n",
    "            for value in annotation:\n",
    "                if flux in value[1]:\n",
    "                    cellmlRef.append((value[1],kappa[k],'fluxUnit'))\n",
    "                    with open('GFG.txt', 'a') as file:\n",
    "                        file.write('\\t\\tvar '+ kappa[k]+': '+'fluxUnit '+'{'+'init: '+value[2]+'}'+';'+'\\n')\n",
    "                        k+=1\n",
    "\n",
    "    # Generating the ODEs       \n",
    "    with open('GFG.txt', 'a') as file:\n",
    "        file.write('\\n')\n",
    "\n",
    "    for i in range(np.shape(N)[0]):\n",
    "        for annotation,ID,unit in cellmlRef:\n",
    "            if all(ele in speciesNoDuplicate[i] for ele in annotation):\n",
    "                with open('GFG.txt', 'a') as file:\n",
    "                    file.write('\\t\\tode('+ID+',t)=')\n",
    "                for j in range(np.shape(N)[1]):  \n",
    "\n",
    "                    if N[i][j] != 0:\n",
    "\n",
    "                        if N[i][j] > 0:\n",
    "                            for annotation2,ID2,unit2 in cellmlRef:\n",
    "                                if V[j] == annotation2:\n",
    "                                    with open('GFG.txt', 'a') as file:\n",
    "                                        file.write('+'+str(N[i][j])+'{dimensionless}*'+ID2)\n",
    "\n",
    "                    if N[i][j] < 0:\n",
    "                        for annotation2,ID2,unit2 in cellmlRef:\n",
    "                            if V[j] == annotation2:\n",
    "                                with open('GFG.txt', 'a') as file:\n",
    "                                    file.write(str(N[i][j])+'{dimensionless}*'+ID2)\n",
    "\n",
    "        with open('GFG.txt', 'a') as file:\n",
    "            file.write(';\\n')\n",
    "\n",
    "\n",
    "    # Generating the reaction rates\n",
    "    with open('GFG.txt', 'a') as file:\n",
    "        file.write('\\n')\n",
    "\n",
    "    for flux in V:\n",
    "        for annotation1,ID1,unit1 in cellmlRef:\n",
    "            if flux == annotation1:\n",
    "                with open('GFG.txt', 'a') as file:\n",
    "                    file.write('\\t\\t '+ ID1+'= ') \n",
    "                for annotation2,ID2,unit2 in cellmlRef:\n",
    "                    if all(el in annotation2  for el in [flux]+['OPB_01296']):\n",
    "                        with open('GFG.txt', 'a') as file:\n",
    "                            file.write(ID2+'*(') \n",
    "        length = 0                    \n",
    "        for stoi,reactant in reaction_reactants[flux]:\n",
    "            length+=1\n",
    "            for annotation,ID,unit in cellmlRef:\n",
    "                if all(el in reactant for el in annotation):\n",
    "                    Q = copy.deepcopy(annotation)\n",
    "                    Q.remove('OPB_00340')\n",
    "                    for annotation2,ID2,unit2 in cellmlRef:\n",
    "                        if all(el in annotation2 for el in Q+['OPB_00079']):\n",
    "                            with open('GFG.txt', 'a') as file:\n",
    "                                file.write('pow('+ID+'*'+ID2+','+str(stoi)+'{dimensionless}'+')') \n",
    "\n",
    "            if length < len(reaction_reactants[flux]):\n",
    "                with open('GFG.txt', 'a') as file:\n",
    "                    file.write(' * ')\n",
    "\n",
    "\n",
    "        with open('GFG.txt', 'a') as file:\n",
    "            file.write(' - ')\n",
    "\n",
    "        length = 0 \n",
    "        for stoi,product in reaction_products[flux]:\n",
    "            length+=1\n",
    "            for annotation,ID,unit in cellmlRef:\n",
    "                if all(el in product for el in annotation):\n",
    "                    Q = copy.deepcopy(annotation)\n",
    "                    Q.remove('OPB_00340')\n",
    "                    for annotation2,ID2,unit2 in cellmlRef:\n",
    "                        if all(el in Q+['OPB_00079'] for el in annotation2):\n",
    "                            with open('GFG.txt', 'a') as file:\n",
    "                                file.write('pow('+ID+'*'+ID2+','+str(stoi)+'{dimensionless}'+')') \n",
    "\n",
    "            if length < len(reaction_products[flux]):\n",
    "                with open('GFG.txt', 'a') as file:\n",
    "                    file.write(' * ')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        with open('GFG.txt', 'a') as file:\n",
    "            file.write(');\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with open('GFG.txt', 'a') as file:\n",
    "        file.write('\\tenddef;'+'\\n'+'enddef;')\n",
    "        \n",
    "    return cellmlRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def pmrSearching(name):\n",
    "    sparqlendpoint = 'https://models.physiomeproject.org/pmr2_virtuoso_search'\n",
    "    sparql = SPARQLWrapper(sparqlendpoint)\n",
    "\n",
    "    def search_entity(terms):\n",
    "        query = \"\"\"SELECT ?graph ?Model_entity WHERE {{ GRAPH ?graph {{ ?Model_entity ?p ?o FILTER REGEX(LCASE(STR(?Model_entity)), '{terms}')}}}}\"\"\".format(terms=terms)\n",
    "        sparql.setQuery(query)\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        graphs = sparql.query().convert()\n",
    "        return graphs\n",
    "\n",
    "    def search_model(terms):\n",
    "        terms = terms.lower()\n",
    "        entities = search_entity(terms)\n",
    "        model = set()\n",
    "        for entity in entities['results']['bindings']:\n",
    "            workspace = entity['graph']['value']\n",
    "            cellml = entity['Model_entity']['value'].split('#')[0]\n",
    "            if not cellml.startswith('http') and terms in cellml.lower():\n",
    "                model.update([workspace+'/rawfile/HEAD/'+cellml])\n",
    "        return list(model)\n",
    "\n",
    "    pmrModel = search_model(name)\n",
    "\n",
    "    return pmrModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def BGmodelBuilder(parametersData,inUse):\n",
    "    reaction_reactants={}\n",
    "    reaction_products={}\n",
    "    for transporterName in parametersData:  \n",
    "        for entity in parametersData[transporterName]:\n",
    "            for reaction in Reactions[inUse[transporterName][0]]:\n",
    "                if transporterName+'_'+reaction in entity[1]:\n",
    "                    reaction_reactants[transporterName+'_'+reaction]=[]\n",
    "                    reaction_products[transporterName+'_'+reaction]=[]\n",
    "                    for stoi in reaction_reactants_templates[inUse[transporterName][0]]:\n",
    "                        for key,values in stoi.items():\n",
    "                            if key == reaction:\n",
    "                                for value in values: # (value[0],value[1])=(1,Ai)\n",
    "                                    for reference in referenceAnnotations[inUse[transporterName][0]]:\n",
    "                                        for ID in reference:\n",
    "                                            for annot in reference[ID]:\n",
    "                                                if ID == value[1]: \n",
    "                                                    for entity0 in parametersData[transporterName]:\n",
    "                                                        if all(element in annot for element in entity0[1]):\n",
    "                                                            X=copy.deepcopy(annot)\n",
    "                                                            X.append(transporterName)\n",
    "                                                            reaction_reactants[transporterName+'_'+reaction].append((value[0],X))\n",
    "                    for stoi in reaction_products_templates[inUse[transporterName][0]]:\n",
    "                        for key,values in stoi.items():\n",
    "                            if key == reaction:\n",
    "                                for value in values: # (value[0],value[1])=(1,Ai)\n",
    "                                    for reference in referenceAnnotations[inUse[transporterName][0]]:\n",
    "                                        for ID in reference:\n",
    "                                            for annot in reference[ID]:\n",
    "                                                if ID == value[1]: \n",
    "                                                    for entity0 in parametersData[transporterName]:\n",
    "                                                        if all(element in annot for element in entity0[1]):\n",
    "                                                            X=copy.deepcopy(annot)\n",
    "                                                            X.append(transporterName)\n",
    "                                                            reaction_products[transporterName+'_'+reaction].append((value[0],X))                                           \n",
    "\n",
    "    V = []\n",
    "    for flux in reaction_reactants:\n",
    "        V.append(flux)\n",
    "\n",
    "    Species = []\n",
    "    for transporterName in parametersData:\n",
    "        for entity in parametersData[transporterName]:\n",
    "            if 'OPB_00340' in entity[1]:\n",
    "                X = copy.deepcopy(entity[1])\n",
    "                X.append(transporterName)\n",
    "                Species.append(X)\n",
    "\n",
    "    speciesNoDuplicate = []\n",
    "    for s in Species:\n",
    "        for transporterName in inUse:\n",
    "            if transporterName in s:\n",
    "                ss = copy.deepcopy(s)\n",
    "                ss.remove(transporterName)\n",
    "                if ss not in speciesNoDuplicate:\n",
    "                    speciesNoDuplicate.append(ss)\n",
    "\n",
    "    speciesConstants=[]\n",
    "    for species in speciesNoDuplicate:\n",
    "        X = copy.deepcopy(species)\n",
    "        X.remove('OPB_00340')\n",
    "        for transporterName in parametersData:\n",
    "            for entity in parametersData[transporterName]:\n",
    "                if all(el in entity[1] for el in ['OPB_00079']+X) and entity[1] not in speciesConstants:\n",
    "                    speciesConstants.append(entity[1])\n",
    "\n",
    "\n",
    "    M=np.zeros((len(Species),len(V)))\n",
    "    for s in range(len(Species)):\n",
    "        for key,i in zip(reaction_products,range(len(reaction_products))):\n",
    "            for stoi,val  in reaction_products[key]:\n",
    "                if all(el in val for el in Species[s]):\n",
    "                    M[s][i] = stoi\n",
    "        for key,i in zip(reaction_reactants,range(len(reaction_reactants))):\n",
    "            for stoi,val in reaction_reactants[key]:\n",
    "                if all(el in val for el in Species[s]):\n",
    "                    M[s][i] = -stoi\n",
    "\n",
    "\n",
    "    N=np.zeros((len(speciesNoDuplicate),len(V)))\n",
    "    for transporterName in inUse:\n",
    "        for v,i in zip(V,range(len(V))):\n",
    "            if transporterName in v:\n",
    "                for s1 in range(len(speciesNoDuplicate)):\n",
    "                    for s2 in range(len(Species)):\n",
    "                        if transporterName in Species[s2]:\n",
    "                            if all(el in Species[s2] for el in speciesNoDuplicate[s1]):\n",
    "                                N[s1][i] = M[s2][i]\n",
    "                                \n",
    "    return [N,V,speciesConstants,speciesNoDuplicate,reaction_reactants,reaction_products]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def pmrRDFsearch(terms):\n",
    "    \n",
    "    sparqlendpoint = 'https://models.physiomeproject.org/pmr2_virtuoso_search'\n",
    "    sparql = SPARQLWrapper(sparqlendpoint)\n",
    "\n",
    "    sparql_tmpl = '''SELECT DISTINCT ?g ?v WHERE {{ GRAPH ?g {{\n",
    "    ?v ?p1 [?p2 ?b; ?p3 [?p4 ?d; ?p5 [?p6 ?f]]] .\n",
    "    FILTER (regex(str(?b),\"{opb}\") && regex(str(?d),\"{chebi}\") && regex(str(?f),\"{fma}\"))\n",
    "    }} }}'''\n",
    "\n",
    "    for c in terms:\n",
    "        if c.startswith('CHEBI'):\n",
    "            chebi = c\n",
    "        elif c.startswith('OPB'):\n",
    "            opb = c\n",
    "        elif c.startswith('FMA'):\n",
    "            fma = c\n",
    "    query = sparql_tmpl.format(opb=opb, chebi=chebi, fma=fma)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    rst =  sparql.query().convert()\n",
    "    if len(rst['results']['bindings']) > 0:\n",
    "        cellmls = {}\n",
    "        for r in rst['results']['bindings']:\n",
    "            cellml_file, cellml_var = r['v']['value'].split('#')\n",
    "            cellml_path = r['g']['value'] + '/rawfile/HEAD/' + cellml_file\n",
    "            if cellml_path not in cellmls:\n",
    "                cellmls[cellml_path] = []\n",
    "            cellmls[cellml_path] += [cellml_var]\n",
    "        return cellmls\n",
    "    return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def minMaxRange(cellmlRef):\n",
    "    valueRange = {}\n",
    "    valueMinMax = {}\n",
    "\n",
    "    PMRmodelsAddress = '/Users/nsha457/Documents/Jupyter_files/CellmlScriptProduction/Exemplar models on PMR'\n",
    "    for file in os.listdir(PMRmodelsAddress):\n",
    "        if file.endswith(\".cellml\"):\n",
    "            [List,rdfs,root] = getAnnotations(PMRmodelsAddress+'/{0}'.format(file))\n",
    "            initialVals = valExtraction(root,List)\n",
    "            for i in range(len(cellmlRef)):\n",
    "                for j in range(len(rdfs)):\n",
    "                    if all(ele in cellmlRef[i][0] for ele in rdfs[j]):\n",
    "                        if cellmlRef[i][1] in valueRange.keys():\n",
    "                            valueRange[cellmlRef[i][1]].append(initialVals[j])\n",
    "                        else:\n",
    "                            valueRange[cellmlRef[i][1]]=[]\n",
    "                            valueRange[cellmlRef[i][1]].append(initialVals[j])   \n",
    "\n",
    "    for key,value in valueRange.items():\n",
    "        valueMinMax[key] = []\n",
    "        valueMinMax[key].append(min(valueRange[key]))\n",
    "        valueMinMax[key].append(max(valueRange[key]))\n",
    "        \n",
    "    return valueMinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we see which group of transporters/channels belong to which template\n",
    "templateGroups = {'SLC2':['SLC2A1','SLC2A2','SLC2A3'],\n",
    "                  'SLC4':['SLC4A1','SLC4A2','SLC4A3']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "referenceAnnotations = {'SLC2': [{'Ai':[['FMA:226050', 'OPB_00340', 'CHEBI:17234'],['FMA:226050', 'OPB_00340', 'CHEBI:28260'],['FMA:226050', 'OPB_00340', 'CHEBI:37684'],['FMA:226050', 'OPB_00340', 'CHEBI:5417']]},\n",
    "                                {'Ao':[['OPB_00340', 'FMA:70022', 'CHEBI:17234'], ['OPB_00340', 'FMA:70022', 'CHEBI:28260'],['OPB_00340', 'FMA:70022', 'CHEBI:37684'],['OPB_00340', 'FMA:70022', 'CHEBI:5417']]},\n",
    "                                {'Ei':[['FMA:226050', 'OPB_00340', 'CHEBI:38807']]},\n",
    "                                {'Eo':[['OPB_00340', 'FMA:70022', 'CHEBI:38807']]},\n",
    "                                {'EAi':[['CHEBI:81851', 'FMA:226050', 'OPB_00340']]},                              \n",
    "                                {'EAo':[['CHEBI:81851', 'OPB_00340', 'FMA:70022']]},\n",
    "                                {'K_Ai':[['OPB_00079', 'FMA:226050', 'CHEBI:17234'], ['OPB_00079', 'FMA:226050', 'CHEBI:28260'], ['OPB_00079', 'FMA:226050', 'CHEBI:37684'], ['OPB_00079', 'FMA:226050', 'CHEBI:5417']]},\n",
    "                                {'K_Ao':[['OPB_00079', 'FMA:70022', 'CHEBI:17234'], ['OPB_00079', 'FMA:70022', 'CHEBI:28260'], ['OPB_00079', 'FMA:70022', 'CHEBI:37684'], ['OPB_00079', 'FMA:70022', 'CHEBI:5417']]},\n",
    "                                {'K_Ei':[['OPB_00079', 'FMA:226050', 'CHEBI:38807']]},\n",
    "                                {'K_Eo':[['OPB_00079', 'FMA:70022', 'CHEBI:38807']]},\n",
    "                                {'K_EAi':[['CHEBI:81851', 'FMA:226050', 'OPB_00079']]},\n",
    "                                {'K_EAo':[['CHEBI:81851', 'FMA:70022', 'OPB_00079']]},\n",
    "                                {'kappa_Re1':[['CHEBI:64297', 'SLC2A1_Re1', 'OPB_01296']]},\n",
    "                                {'kappa_Re2':[['SLC2A1_Re2', 'CHEBI:64297', 'OPB_01296']]},\n",
    "                                {'kappa_Re3':[['CHEBI:64297', 'SLC2A1_Re3', 'OPB_01296']]},\n",
    "                                {'kappa_Re4':[['SLC2A1_Re4', 'CHEBI:64297', 'OPB_01296']]},],\n",
    "                       'SLC4': [{'Ai':[['FMA:226050', 'OPB_00340', 'CHEBI:17234'],[\"randomRDF17\"]]},\n",
    "                                {'Ao':[['OPB_00340', 'FMA:70022', 'CHEBI:17234'], [\"randomRDF18\"]]},\n",
    "                                {'Ei':[['CHEBI:39000', 'OPB_00340', 'FMA:226050'], [\"randomRDF19\"]]},\n",
    "                                {'Eo':[['CHEBI:39000', 'OPB_00340', 'FMA:70022'], [\"randomRDF20\"]]},\n",
    "                                {'EAi':[['CHEBI:31340', 'FMA:226050', 'OPB_00340'], [\"randomRDF21\"]]},\n",
    "                                {'EAo':[['CHEBI:31340', 'FMA:70022', 'OPB_00340'], [\"randomRDF22\"]]},\n",
    "                                {'Bi':[['OPB_00340', 'FMA:226050', 'CHEBI:29101'], [\"randomRDF23\"]]},\n",
    "                                {'Bo':[['OPB_00340', 'FMA:70022', 'CHEBI:29101'], [\"randomRDF24\"]]},\n",
    "                                {'EBi':[['OPB_00340', 'FMA:226050', 'CHEBI:62965'], [\"randomRDF25\"]]},\n",
    "                                {'EBo':[['OPB_00340', 'FMA:70022', 'CHEBI:62965'], [\"randomRDF26\"]]},\n",
    "                                {'K_Ai':[['FMA:226050', 'CHEBI:17234', 'OPB_00079'],[\"randomRDF27\"]]},\n",
    "                                {'K_Ao':[['OPB_00079', 'FMA:70022', 'CHEBI:17234'], [\"randomRDF28\"]]},\n",
    "                                {'K_Ei':[['CHEBI:39000', 'OPB_00079', 'FMA:226050'], [\"randomRDF29\"]]},\n",
    "                                {'K_Eo':[['CHEBI:39000', 'OPB_00079', 'FMA:70022'], [\"randomRDF30\"]]},\n",
    "                                {'K_EAi':[['CHEBI:31340', 'OPB_00079', 'FMA:226050'], [\"randomRDF31\"]]},\n",
    "                                {'K_EAo':[['CHEBI:31340', 'OPB_00079', 'FMA:70022'], [\"randomRDF32\"]]},\n",
    "                                {'K_Bi':[['OPB_00079', 'FMA:226050', 'CHEBI:29101'], [\"randomRDF33\"]]},\n",
    "                                {'K_Bo':[['OPB_00079', 'FMA:70022', 'CHEBI:29101'], [\"randomRDF34\"]]},\n",
    "                                {'K_EBi':[['OPB_00079', 'FMA:226050', 'CHEBI:62965'], [\"randomRDF35\"]]},\n",
    "                                {'K_EBo':[['OPB_00079', 'FMA:70022', 'CHEBI:62965'], [\"randomRDF36\"]]},\n",
    "                                {'kappa_Re1':[['CHEBI:64297', 'SLC4A1_Re1', 'OPB_01296'], [\"randomRDF37\"]]},\n",
    "                                {'kappa_Re2':[['CHEBI:64297', 'SLC4A1_Re2', 'OPB_01296'], [\"randomRDF38\"]]},\n",
    "                                {'kappa_Re3':[['CHEBI:64297', 'SLC4A1_Re3', 'OPB_01296'], [\"randomRDF39\"]]},\n",
    "                                {'kappa_Re4':[['CHEBI:64297', 'SLC4A1_Re4', 'OPB_01296'], [\"randomRDF40\"]]},\n",
    "                                {'kappa_Re5':[['CHEBI:64297', 'SLC4A1_Re5', 'OPB_01296'], [\"randomRDF41\"]]},\n",
    "                                {'kappa_Re6':[['CHEBI:64297', 'SLC4A1_Re6', 'OPB_01296'], [\"randomRDF42\"]]},\n",
    "                               ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reactions={'SLC2': ['Re1', 'Re2', 'Re3', 'Re4'],\n",
    "           'SLC4': ['Re1', 'Re2', 'Re3', 'Re4', 'Re5', 'Re6']}\n",
    "\n",
    "reaction_reactants_templates={'SLC2': [{'Re1':[(1,'EAi')]}, {'Re2':[(1,'Eo'),(1,'Ao')]}, {'Re3':[(1,'Ei')]}, {'Re4':[(1,'EAo')]}],\n",
    "                              'SLC4': [{'Re1':[(1,'Ao'),(1,'Eo')]}, {'Re2':[(1,'EAi')]}, {'Re3':[(1,'EBo')]}, {'Re4':[(1,'Bi'),(1,'Ei')]}, {'Re5':[(1,'EBi')]}, {'Re6':[(1,'EAo')]}]   }\n",
    "\n",
    "reaction_products_templates={'SLC2': [{'Re1':[(1,'Ai'),(1,'Ei')]}, {'Re2':[(1,'EAo')]}, {'Re3':[(1,'Eo')]}, {'Re4':[(1,'EAi')]}],\n",
    "                             'SLC4': [{'Re1':[(1,'EAo')]}, {'Re2':[(1,'Ai'),(1,'Ei')]}, {'Re3':[(1,'Bo'),(1,'Eo')]}, {'Re4':[(1,'EBi')]}, {'Re5':[(1,'EBo')]}, {'Re6':[(1,'EAi')]}]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa49895bac694ad69e4e86e10081227b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Dropdown(description='Select your first model:', options=('SLC2A1', 'SLC4A1'), s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "channelSelection1 = widgets.Dropdown(\n",
    "            options=['SLC2A1', 'SLC4A1'],\n",
    "            description='Select your first model:',\n",
    "    style={'description_width': 'initial'},\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "channelSelection2 = widgets.Dropdown(\n",
    "            options=['SLC2A1', 'SLC4A1'],\n",
    "            description='Select your second model:',\n",
    "    style={'description_width': 'initial'},\n",
    "            disabled=False\n",
    "        )\n",
    "       \n",
    "button_search = widgets.Button(\n",
    "                description='Search on PMR',\n",
    "                tooltip='Search',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "\n",
    "output = widgets.Output(layout={'border': '1px solid black'})\n",
    "def on_button_clicked1(event):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        channelSelected = [channelSelection1.value,channelSelection2.value]\n",
    "        inUse={}\n",
    "        for selected in channelSelected:\n",
    "            for key in templateGroups.keys():\n",
    "                for transporterName,i in zip(templateGroups[key],range(len(templateGroups[key]))):\n",
    "                    if selected == transporterName:\n",
    "                        inUse[selected]=[]\n",
    "                        inUse[transporterName].append(key)\n",
    "                        \n",
    "        pmrModel1 = pmrSearching(channelSelection1.value)\n",
    "        pmrModel2 = pmrSearching(channelSelection2.value)\n",
    "        \n",
    "        print(f\"The first TEMPLATE is {inUse[channelSelection1.value][0]} with the link to the parameterset: {pmrModel1[0]}\")\n",
    "        print(f\"The second TEMPLATE is {inUse[channelSelection2.value][0]} with the link to the parameterset: {pmrModel2[0]}\")\n",
    "        \n",
    "        \n",
    "            \n",
    "button_search.on_click(on_button_clicked1)\n",
    "vbox_result = widgets.VBox([button_search, output])   \n",
    "\n",
    "vbox_text = widgets.VBox([channelSelection1, channelSelection2, vbox_result])\n",
    "page1 = widgets.HBox([vbox_text])\n",
    "\n",
    "display(page1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: The Steady-states (SS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8ff2342b694db6ab3ed4b7bb2a22bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Button(description='Show SS', style=ButtonStyle(), tooltip='Description'), Outpu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "button_properties = widgets.Button(\n",
    "                description='Show SS',\n",
    "                tooltip='Description',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "output2 = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "def on_button_clicked2(event):\n",
    "    with output2:\n",
    "        clear_output()\n",
    "        \n",
    "        channelSelected = [channelSelection1.value,channelSelection2.value]\n",
    "        inUse={}\n",
    "        for selected in channelSelected:\n",
    "            for key in templateGroups.keys():\n",
    "                for transporterName,i in zip(templateGroups[key],range(len(templateGroups[key]))):\n",
    "                    if selected == transporterName:\n",
    "                        inUse[selected]=[]\n",
    "                        inUse[transporterName].append(key)\n",
    "\n",
    "        annotations={}\n",
    "        for transporterName in inUse:\n",
    "            addressP = '/Users/nsha457/Documents/Jupyter_files/CellmlScriptProduction/enzymes/{0}.cellml'.format(transporterName)\n",
    "            [List,rdfs,root] = getAnnotations(addressP)\n",
    "            initialVals = valExtraction(root,List)\n",
    "            annotations[transporterName] = []\n",
    "            annotations[transporterName] = [List,rdfs,initialVals]\n",
    "\n",
    "        parametersData = {}\n",
    "        for key in annotations:\n",
    "            parametersData[key] = []\n",
    "            for j in range(len(annotations[key][0])):\n",
    "                parametersData[key].append([annotations[key][0][j],annotations[key][1][j],annotations[key][2][j]])\n",
    "\n",
    "\n",
    "        refInUse = {'SLC2A1': ['GLUT2'], 'SLC4A1': ['GLUT4']}\n",
    "\n",
    "        annotations_ref={}\n",
    "        df_RefModels = {}\n",
    "        for transporterName in refInUse:\n",
    "            addressRefModels = './{0}.cellml'.format(refInUse[transporterName][0])\n",
    "            addressRefData = './{0}.csv'.format(refInUse[transporterName][0])\n",
    "\n",
    "            [List_ref,rdfs_ref,root_ref] = getAnnotations(addressRefModels)\n",
    "            initialVals_ref = valExtraction(root_ref,List_ref)\n",
    "            annotations_ref[transporterName] = []\n",
    "            annotations_ref[transporterName] = [List_ref,rdfs_ref,initialVals_ref]\n",
    "\n",
    "            df_RefModels[transporterName] = pd.read_csv(addressRefData)\n",
    "\n",
    "        parametersData_ref = {}\n",
    "        for key in annotations_ref:\n",
    "            parametersData_ref[key] = []\n",
    "            for j in range(len(annotations_ref[key][0])):\n",
    "                parametersData_ref[key].append([annotations_ref[key][0][j],annotations_ref[key][1][j],annotations_ref[key][2][j]])\n",
    "\n",
    "\n",
    "        SS = {}  \n",
    "        pmrModelSimilarRDF={}\n",
    "        for key,values in parametersData.items():\n",
    "            SS[key]={}\n",
    "            for value in values:\n",
    "                for value_ref in parametersData_ref[key]:\n",
    "                    if all(el in value[1] for el in value_ref[1]):\n",
    "\n",
    "                        SS[key][value_ref[0]] = df_RefModels[key][[x for x in df_RefModels[key].columns if x == value_ref[0]]].values[-1][0]\n",
    "#                         pmrModelSimilarRDF[value[0]] = pmrRDFsearch(value[1])\n",
    "                        \n",
    "\n",
    "        text_0 = widgets.HTML(value=\"<h5><b>According to PMR, your selected protein {} should have the following SS values:<b><h5>\".format(channelSelection1.value))\n",
    "        display(text_0)\n",
    "#         text_00 = widgets.HTML(value=\"<h5><b>Models are:<b><h5>\")\n",
    "#         display(text_00)\n",
    "#         print(f\"{list(pmrModelSimilarRDF.values())}\")\n",
    "\n",
    "        print(f\"{SS[channelSelection1.value]}\\n\")\n",
    "        text_1 = widgets.HTML(value=\"<h5><b>According to PMR, your selected protein {} should have the following SS values:<b><h5>\".format(channelSelection2.value))\n",
    "        display(text_1)\n",
    "        print(f\"{SS[channelSelection2.value]}\\n\")\n",
    "                \n",
    "button_properties.on_click(on_button_clicked2)\n",
    "vbox_result = widgets.VBox([button_properties, output2]) \n",
    "\n",
    "page2 = widgets.HBox([vbox_result])\n",
    "\n",
    "display(page2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Model composition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "code_folding": [
     21,
     29,
     39,
     51,
     58
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807d712a759443bdbb623578b0e83a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Button(description='Compose models', style=ButtonStyle(), tooltip='Description')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button_compose = widgets.Button(\n",
    "                description='Compose models',\n",
    "                tooltip='Description',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "output3 = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "def on_button_clicked3(event):\n",
    "    with output3:\n",
    "#         clear_output()\n",
    "        \n",
    "        channelSelected = [channelSelection1.value,channelSelection2.value]\n",
    "        inUse={}\n",
    "        for selected in channelSelected:\n",
    "            for key in templateGroups.keys():\n",
    "                for transporterName,i in zip(templateGroups[key],range(len(templateGroups[key]))):\n",
    "                    if selected == transporterName:\n",
    "                        inUse[selected]=[]\n",
    "                        inUse[transporterName].append(key)\n",
    "\n",
    "        annotations={}\n",
    "        for transporterName in inUse:\n",
    "            addressP = '/Users/nsha457/Documents/Jupyter_files/CellmlScriptProduction/enzymes/{0}.cellml'.format(transporterName)\n",
    "            [List,rdfs,root] = getAnnotations(addressP)\n",
    "            initialVals = valExtraction(root,List)\n",
    "            annotations[transporterName] = []\n",
    "            annotations[transporterName] = [List,rdfs,initialVals]\n",
    "\n",
    "        parametersData = {}\n",
    "        for key in annotations:\n",
    "            parametersData[key] = []\n",
    "            for j in range(len(annotations[key][0])):\n",
    "                parametersData[key].append([annotations[key][0][j],annotations[key][1][j],annotations[key][2][j]])\n",
    "\n",
    "\n",
    "        refInUse = {'SLC2A1': ['GLUT2'], 'SLC4A1': ['GLUT4']}\n",
    "\n",
    "        annotations_ref={}\n",
    "        df_RefModels = {}\n",
    "        for transporterName in refInUse:\n",
    "            addressRefModels = './{0}.cellml'.format(refInUse[transporterName][0])\n",
    "            addressRefData = './{0}.csv'.format(refInUse[transporterName][0])\n",
    "\n",
    "            [List_ref,rdfs_ref,root_ref] = getAnnotations(addressRefModels)\n",
    "            initialVals_ref = valExtraction(root_ref,List_ref)\n",
    "            annotations_ref[transporterName] = []\n",
    "            annotations_ref[transporterName] = [List_ref,rdfs_ref,initialVals_ref]\n",
    "\n",
    "            df_RefModels[transporterName] = pd.read_csv(addressRefData)\n",
    "\n",
    "        parametersData_ref = {}\n",
    "        for key in annotations_ref:\n",
    "            parametersData_ref[key] = []\n",
    "            for j in range(len(annotations_ref[key][0])):\n",
    "                parametersData_ref[key].append([annotations_ref[key][0][j],annotations_ref[key][1][j],annotations_ref[key][2][j]])\n",
    "\n",
    "\n",
    "        SS = {}        \n",
    "        for key,values in parametersData.items():\n",
    "            SS[key]={}\n",
    "            for value in values:\n",
    "                for value_ref in parametersData_ref[key]:\n",
    "                    if all(el in value[1] for el in value_ref[1]):\n",
    "\n",
    "                        SS[key][value_ref[0]] = df_RefModels[key][[x for x in df_RefModels[key].columns if x == value_ref[0]]].values[-1][0]\n",
    "\n",
    "\n",
    "\n",
    "        [parametersData,mutualVars] = checkMutual(parametersData)\n",
    "        \n",
    "\n",
    "        [N,V,speciesConstants,speciesNoDuplicate,reaction_reactants,reaction_products]=BGmodelBuilder(parametersData,inUse)\n",
    "                                    \n",
    "        cellmlRef = textFileGen(speciesNoDuplicate,parametersData,speciesConstants,reaction_reactants,V,N,reaction_products)\n",
    "            \n",
    "        valueMinMax = minMaxRange(cellmlRef)\n",
    "        \n",
    "        text_0 = widgets.HTML(value=\"<h3>We found the following ranges for the following parameters:<h3>\")\n",
    "        display(text_0)\n",
    "#         print(valueMinMax,'\\n')\n",
    "        \n",
    "        \n",
    "            \n",
    "        q_9=widgets.RadioButtons(options=[float(valueMinMax['q_9'][0])])\n",
    "        K_9=widgets.RadioButtons(options=[float(valueMinMax['K_9'][0])]) \n",
    "        q_10=FloatSlider(min=float(valueMinMax['q_10'][0]),max=float(valueMinMax['q_10'][1]),step=0.001,layout=widgets.Layout(width='75%'), readout_format='.3f')\n",
    "        K_10=FloatSlider(min=float(valueMinMax['K_10'][0]),max=float(valueMinMax['K_10'][1]),step=0.001,layout=widgets.Layout(width='75%'), readout_format='.3f')\n",
    "        \n",
    "        def plotf(q_9,K_9,q_10,K_10):\n",
    "            plt.figure(figsize=(5,5))\n",
    "            x = np.linspace(0, 100, num=100)\n",
    "            plt.plot(x, np.ones(100)*(K_9*q_10*4*4*8-K_10*2*70)*1e-6,label='Glucose_i',color='r', linewidth=2) #SS relationship for q_9\n",
    "            plt.plot(x, np.ones(100)*(K_10*30*3*2-2*2*K_9*q_9*8)*1e-6,label='Sodium_i',color='steelblue', linewidth=2) # SS relationship for q_10\n",
    "            plt.grid(color='gray', linestyle='-', linewidth=0.5)\n",
    "            plt.ylabel('Concentration')\n",
    "            plt.title('Steady-state concentrations')\n",
    "            plt.legend(loc='best')\n",
    "            plt.show()\n",
    "            return \n",
    "        \n",
    "        interact(plotf, q_9=q_9, K_9=K_9, q_10=q_10, K_10=K_10)\n",
    "        \n",
    "        # Create the button widget\n",
    "        button = widgets.Button(description='Save number')\n",
    "        # Define a function to handle the button click event\n",
    "        def save_number(button_click):\n",
    "            selected_number = {'q_9':q_9.value,'K_9':K_9.value,'q_10':q_10.value,'K_10':K_10.value}\n",
    "            with open('selected_number.txt', 'w') as f:\n",
    "                f.write(str(selected_number))\n",
    "            print(f'Number {selected_number} saved to file.')\n",
    "\n",
    "        # Attach the save_number function to the button click event\n",
    "        button.on_click(save_number)\n",
    "        # Display the widgets\n",
    "        display(button)\n",
    "\n",
    "\n",
    "    return \n",
    "\n",
    "        \n",
    "\n",
    "button_compose.on_click(on_button_clicked3)\n",
    "vbox_result = widgets.VBox([button_compose, output3]) \n",
    "page3 = widgets.HBox([vbox_result])\n",
    "display(page3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5624ceada30c42f89dfec5f5a42dd90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(options=(), value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q_9=widgets.RadioButtons()\n",
    "display(q_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Model rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_cellml = widgets.Button(\n",
    "                description='Generate code',\n",
    "                tooltip='Description',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "output4 = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "def on_button_clicked4(event):\n",
    "    with output4:\n",
    "        text_0 = widgets.HTML(value=\"<h3>The generated CellML code for the composition of SLC2A1 & SLC4A1 is:</h3>\")\n",
    "        vbox_text = widgets.VBox([text_0])\n",
    "        display(vbox_text)\n",
    "        with open('GFG.txt') as f:\n",
    "            contents = f.read()\n",
    "        print(contents)\n",
    "\n",
    "button_cellml.on_click(on_button_clicked4)\n",
    "vbox_result = widgets.VBox([button_cellml, output4]) \n",
    "display(vbox_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
